{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor, Pool, cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, Module, ModuleList\n",
    "\n",
    "from torch_frame.data import Dataset, DataLoader\n",
    "from torch_frame import TensorFrame, stype\n",
    "from torch_frame.nn.conv import TabTransformerConv\n",
    "from torch_frame.nn.encoder import (\n",
    "    EmbeddingEncoder,\n",
    "    LinearEncoder,\n",
    "    StypeWiseFeatureEncoder,\n",
    ")\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    # For categorical features, replace NA with \"Missing\"\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "    for key in categorical_columns:\n",
    "        df[key] = df[key].astype('category').cat.add_categories(\"Missing\").fillna(\"Missing\")\n",
    "    # categorical_columns = df.select_dtypes(include=['category']).columns\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFrame(\n",
       "  num_cols=79,\n",
       "  num_rows=1460,\n",
       "  categorical (43): ['Alley', 'BldgType', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'BsmtQual', 'CentralAir', 'Condition1', 'Condition2', 'Electrical', 'ExterCond', 'ExterQual', 'Exterior1st', 'Exterior2nd', 'Fence', 'FireplaceQu', 'Foundation', 'Functional', 'GarageCond', 'GarageFinish', 'GarageQual', 'GarageType', 'Heating', 'HeatingQC', 'HouseStyle', 'KitchenQual', 'LandContour', 'LandSlope', 'LotConfig', 'LotShape', 'MSZoning', 'MasVnrType', 'MiscFeature', 'Neighborhood', 'PavedDrive', 'PoolQC', 'RoofMatl', 'RoofStyle', 'SaleCondition', 'SaleType', 'Street', 'Utilities'],\n",
       "  numerical (36): ['1stFlrSF', '2ndFlrSF', '3SsnPorch', 'BedroomAbvGr', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtFullBath', 'BsmtHalfBath', 'BsmtUnfSF', 'EnclosedPorch', 'Fireplaces', 'FullBath', 'GarageArea', 'GarageCars', 'GarageYrBlt', 'GrLivArea', 'HalfBath', 'KitchenAbvGr', 'LotArea', 'LotFrontage', 'LowQualFinSF', 'MSSubClass', 'MasVnrArea', 'MiscVal', 'MoSold', 'OpenPorchSF', 'OverallCond', 'OverallQual', 'PoolArea', 'ScreenPorch', 'TotRmsAbvGrd', 'TotalBsmtSF', 'WoodDeckSF', 'YearBuilt', 'YearRemodAdd', 'YrSold'],\n",
       "  has_target=True,\n",
       "  device='cpu',\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file_path = \"data/house-prices/train.csv\"\n",
    "dataset_df = pd.read_csv(train_file_path)\n",
    "dataset_df = dataset_df.drop('Id', axis=1)\n",
    "target_column = 'SalePrice'\n",
    "dataset_df = prepare_dataset(dataset_df)\n",
    "col_to_stype = {key: stype.categorical for key in dataset_df.select_dtypes(include=['category']).columns.to_list()}\n",
    "col_to_stype.update({key: stype.numerical for key in dataset_df.select_dtypes(exclude=['category']).columns.to_list()})\n",
    "dataset = Dataset(dataset_df, col_to_stype=col_to_stype, target_col=target_column)\n",
    "dataset.materialize()\n",
    "\n",
    "dataset.tensor_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleTransformer(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels, out_channels, num_layers, num_heads,\n",
    "        col_stats, col_names_dict,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = StypeWiseFeatureEncoder(\n",
    "            out_channels=channels,\n",
    "            col_stats=col_stats,\n",
    "            col_names_dict=col_names_dict,\n",
    "            stype_encoder_dict={\n",
    "                stype.categorical: EmbeddingEncoder(),\n",
    "                stype.numerical: LinearEncoder()\n",
    "            },\n",
    "        )\n",
    "        self.convs = ModuleList([\n",
    "            TabTransformerConv(\n",
    "                channels=channels,\n",
    "                num_heads=num_heads,\n",
    "            ) for _ in range(num_layers)\n",
    "        ])\n",
    "        self.decoder = Linear(channels, out_channels)\n",
    "\n",
    "    def forward(self, tf: TensorFrame) -> Tensor:\n",
    "        x, _ = self.encoder(tf)\n",
    "        for conv in self.convs:\n",
    "            x = conv(x)\n",
    "        out = self.decoder(x.mean(dim=1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Epoch 0===\n",
      "average loss = 39039305767.27671\n",
      "===Epoch 1===\n",
      "average loss = 39039304487.97808\n",
      "===Epoch 2===\n",
      "average loss = 39039305469.89589\n",
      "===Epoch 3===\n",
      "average loss = 39039304673.139725\n",
      "===Epoch 4===\n",
      "average loss = 39039304431.86849\n",
      "===Epoch 5===\n",
      "average loss = 39039304246.70685\n",
      "===Epoch 6===\n",
      "average loss = 39039305138.84931\n",
      "===Epoch 7===\n",
      "average loss = 39039305251.0685\n",
      "===Epoch 8===\n",
      "average loss = 39039305385.73151\n",
      "===Epoch 9===\n",
      "average loss = 39039305015.40822\n",
      "===Epoch 10===\n",
      "average loss = 39039304555.309586\n",
      "===Epoch 11===\n",
      "average loss = 39039304465.53425\n",
      "===Epoch 12===\n",
      "average loss = 39039303982.99178\n",
      "===Epoch 13===\n",
      "average loss = 39039303926.882195\n",
      "===Epoch 14===\n",
      "average loss = 39039305290.34521\n",
      "===Epoch 15===\n",
      "average loss = 39039303921.27123\n",
      "===Epoch 16===\n",
      "average loss = 39039305800.94247\n",
      "===Epoch 17===\n",
      "average loss = 39039304925.63287\n",
      "===Epoch 18===\n",
      "average loss = 39039305004.1863\n",
      "===Epoch 19===\n",
      "average loss = 39039305991.715065\n",
      "===Epoch 20===\n",
      "average loss = 39039304454.31233\n",
      "===Epoch 21===\n",
      "average loss = 39039305060.29589\n",
      "===Epoch 22===\n",
      "average loss = 39039305206.180824\n",
      "===Epoch 23===\n",
      "average loss = 39039305026.630135\n",
      "===Epoch 24===\n",
      "average loss = 39039305026.630135\n",
      "===Epoch 25===\n",
      "average loss = 39039304667.52877\n",
      "===Epoch 26===\n",
      "average loss = 39039305217.40274\n",
      "===Epoch 27===\n",
      "average loss = 39039303915.66027\n",
      "===Epoch 28===\n",
      "average loss = 39039304734.860275\n",
      "===Epoch 29===\n",
      "average loss = 39039304768.526024\n",
      "===Epoch 30===\n",
      "average loss = 39039304207.43014\n",
      "===Epoch 31===\n",
      "average loss = 39039304588.97534\n",
      "===Epoch 32===\n",
      "average loss = 39039304656.30685\n",
      "===Epoch 33===\n",
      "average loss = 39039305509.1726\n",
      "===Epoch 34===\n",
      "average loss = 39039305408.17534\n",
      "===Epoch 35===\n",
      "average loss = 39039306047.82466\n",
      "===Epoch 36===\n",
      "average loss = 39039304970.520546\n",
      "===Epoch 37===\n",
      "average loss = 39039305127.627396\n",
      "===Epoch 38===\n",
      "average loss = 39039305071.51781\n",
      "===Epoch 39===\n",
      "average loss = 39039305666.27945\n",
      "===Epoch 40===\n",
      "average loss = 39039305251.0685\n",
      "===Epoch 41===\n",
      "average loss = 39039305464.284935\n",
      "===Epoch 42===\n",
      "average loss = 39039304117.65479\n",
      "===Epoch 43===\n",
      "average loss = 39039304891.967125\n",
      "===Epoch 44===\n",
      "average loss = 39039304252.31781\n",
      "===Epoch 45===\n",
      "average loss = 39039304667.52877\n",
      "===Epoch 46===\n",
      "average loss = 39039305385.73151\n",
      "===Epoch 47===\n",
      "average loss = 39039304600.19726\n",
      "===Epoch 48===\n",
      "average loss = 39039304443.09041\n",
      "===Epoch 49===\n",
      "average loss = 39039304499.2\n",
      "===Epoch 50===\n",
      "average loss = 39039303623.89041\n",
      "===Epoch 51===\n",
      "average loss = 39039303971.76986\n",
      "===Epoch 52===\n",
      "average loss = 39039304689.9726\n",
      "===Epoch 53===\n",
      "average loss = 39039304757.30411\n",
      "===Epoch 54===\n",
      "average loss = 39039304858.30137\n",
      "===Epoch 55===\n",
      "average loss = 39039304504.81096\n",
      "===Epoch 56===\n",
      "average loss = 39039304824.63562\n",
      "===Epoch 57===\n",
      "average loss = 39039305868.27397\n",
      "===Epoch 58===\n",
      "average loss = 39039305217.40274\n",
      "===Epoch 59===\n",
      "average loss = 39039303938.10411\n",
      "===Epoch 60===\n",
      "average loss = 39039304622.6411\n",
      "===Epoch 61===\n",
      "average loss = 39039305699.945206\n",
      "===Epoch 62===\n",
      "average loss = 39039305800.94247\n",
      "===Epoch 63===\n",
      "average loss = 39039305284.734245\n",
      "===Epoch 64===\n",
      "average loss = 39039305105.18356\n",
      "===Epoch 65===\n",
      "average loss = 39039305307.178085\n",
      "===Epoch 66===\n",
      "average loss = 39039304712.416435\n",
      "===Epoch 67===\n",
      "average loss = 39039304746.08219\n",
      "===Epoch 68===\n",
      "average loss = 39039304072.76712\n",
      "===Epoch 69===\n",
      "average loss = 39039304218.652054\n",
      "===Epoch 70===\n",
      "average loss = 39039305643.83562\n",
      "===Epoch 71===\n",
      "average loss = 39039303421.89589\n",
      "===Epoch 72===\n",
      "average loss = 39039306047.82466\n",
      "===Epoch 73===\n",
      "average loss = 39039304701.19452\n",
      "===Epoch 74===\n",
      "average loss = 39039304095.21096\n",
      "===Epoch 75===\n",
      "average loss = 39039304689.9726\n",
      "===Epoch 76===\n",
      "average loss = 39039304824.63562\n",
      "===Epoch 77===\n",
      "average loss = 39039305127.627396\n",
      "===Epoch 78===\n",
      "average loss = 39039304936.8548\n",
      "===Epoch 79===\n",
      "average loss = 39039305307.178085\n",
      "===Epoch 80===\n",
      "average loss = 39039305273.51233\n",
      "===Epoch 81===\n",
      "average loss = 39039304880.74521\n",
      "===Epoch 82===\n",
      "average loss = 39039305307.178085\n",
      "===Epoch 83===\n",
      "average loss = 39039305026.630135\n",
      "===Epoch 84===\n",
      "average loss = 39039305116.40548\n",
      "===Epoch 85===\n",
      "average loss = 39039304370.14794\n",
      "===Epoch 86===\n",
      "average loss = 39039304790.969864\n",
      "===Epoch 87===\n",
      "average loss = 39039305744.83288\n",
      "===Epoch 88===\n",
      "average loss = 39039303702.44383\n",
      "===Epoch 89===\n",
      "average loss = 39039304431.86849\n",
      "===Epoch 90===\n",
      "average loss = 39039305677.50137\n",
      "===Epoch 91===\n",
      "average loss = 39039304431.86849\n",
      "===Epoch 92===\n",
      "average loss = 39039304678.75069\n",
      "===Epoch 93===\n",
      "average loss = 39039304353.31507\n",
      "===Epoch 94===\n",
      "average loss = 39039304600.19726\n",
      "===Epoch 95===\n",
      "average loss = 39039306002.93699\n",
      "===Epoch 96===\n",
      "average loss = 39039305138.84931\n",
      "===Epoch 97===\n",
      "average loss = 39039304386.98082\n",
      "===Epoch 98===\n",
      "average loss = 39039304757.30411\n",
      "===Epoch 99===\n",
      "average loss = 39039305060.29589\n",
      "===Epoch 100===\n",
      "average loss = 39039304790.969864\n",
      "===Epoch 101===\n",
      "average loss = 39039305060.29589\n",
      "===Epoch 102===\n",
      "average loss = 39039304723.63836\n",
      "===Epoch 103===\n",
      "average loss = 39039303792.21918\n",
      "===Epoch 104===\n",
      "average loss = 39039305453.06301\n",
      "===Epoch 105===\n",
      "average loss = 39039304325.26028\n",
      "===Epoch 106===\n",
      "average loss = 39039305150.071236\n",
      "===Epoch 107===\n",
      "average loss = 39039305183.736984\n",
      "===Epoch 108===\n",
      "average loss = 39039304970.520546\n",
      "===Epoch 109===\n",
      "average loss = 39039305307.178085\n",
      "===Epoch 110===\n",
      "average loss = 39039305105.18356\n",
      "===Epoch 111===\n",
      "average loss = 39039304695.583565\n",
      "===Epoch 112===\n",
      "average loss = 39039305082.73972\n",
      "===Epoch 113===\n",
      "average loss = 39039304544.08767\n",
      "===Epoch 114===\n",
      "average loss = 39039304241.095894\n",
      "===Epoch 115===\n",
      "average loss = 39039304252.31781\n",
      "===Epoch 116===\n",
      "average loss = 39039304656.30685\n",
      "===Epoch 117===\n",
      "average loss = 39039304072.76712\n",
      "===Epoch 118===\n",
      "average loss = 39039305946.8274\n",
      "===Epoch 119===\n",
      "average loss = 39039304487.97808\n",
      "===Epoch 120===\n",
      "average loss = 39039305453.06301\n",
      "===Epoch 121===\n",
      "average loss = 39039304667.52877\n",
      "===Epoch 122===\n",
      "average loss = 39039304106.43288\n",
      "===Epoch 123===\n",
      "average loss = 39039305475.50685\n",
      "===Epoch 124===\n",
      "average loss = 39039305497.95068\n",
      "===Epoch 125===\n",
      "average loss = 39039305206.180824\n",
      "===Epoch 126===\n",
      "average loss = 39039305295.95616\n",
      "===Epoch 127===\n",
      "average loss = 39039304701.19452\n",
      "===Epoch 128===\n",
      "average loss = 39039305166.904106\n",
      "===Epoch 129===\n",
      "average loss = 39039304342.09315\n",
      "===Epoch 130===\n",
      "average loss = 39039304487.97808\n",
      "===Epoch 131===\n",
      "average loss = 39039305015.40822\n",
      "===Epoch 132===\n",
      "average loss = 39039304948.07671\n",
      "===Epoch 133===\n",
      "average loss = 39039304319.649315\n",
      "===Epoch 134===\n",
      "average loss = 39039304880.74521\n",
      "===Epoch 135===\n",
      "average loss = 39039304723.63836\n",
      "===Epoch 136===\n",
      "average loss = 39039305643.83562\n",
      "===Epoch 137===\n",
      "average loss = 39039304723.63836\n",
      "===Epoch 138===\n",
      "average loss = 39039304790.969864\n",
      "===Epoch 139===\n",
      "average loss = 39039303708.054794\n",
      "===Epoch 140===\n",
      "average loss = 39039306597.69863\n",
      "===Epoch 141===\n",
      "average loss = 39039304768.526024\n",
      "===Epoch 142===\n",
      "average loss = 39039303769.775345\n",
      "===Epoch 143===\n",
      "average loss = 39039304521.64384\n",
      "===Epoch 144===\n",
      "average loss = 39039304847.07945\n",
      "===Epoch 145===\n",
      "average loss = 39039304588.97534\n",
      "===Epoch 146===\n",
      "average loss = 39039304588.97534\n",
      "===Epoch 147===\n",
      "average loss = 39039305441.841095\n",
      "===Epoch 148===\n",
      "average loss = 39039305093.96165\n",
      "===Epoch 149===\n",
      "average loss = 39039304353.31507\n",
      "===Epoch 150===\n",
      "average loss = 39039305363.287674\n",
      "===Epoch 151===\n",
      "average loss = 39039304600.19726\n",
      "===Epoch 152===\n",
      "average loss = 39039304039.10137\n",
      "===Epoch 153===\n",
      "average loss = 39039304914.41096\n",
      "===Epoch 154===\n",
      "average loss = 39039304689.9726\n",
      "===Epoch 155===\n",
      "average loss = 39039304936.8548\n",
      "===Epoch 156===\n",
      "average loss = 39039303825.88493\n",
      "===Epoch 157===\n",
      "average loss = 39039305127.627396\n",
      "===Epoch 158===\n",
      "average loss = 39039305127.627396\n",
      "===Epoch 159===\n",
      "average loss = 39039305071.51781\n",
      "===Epoch 160===\n",
      "average loss = 39039304285.98356\n",
      "===Epoch 161===\n",
      "average loss = 39039305206.180824\n",
      "===Epoch 162===\n",
      "average loss = 39039304645.08493\n",
      "===Epoch 163===\n",
      "average loss = 39039305537.227394\n",
      "===Epoch 164===\n",
      "average loss = 39039304465.53425\n",
      "===Epoch 165===\n",
      "average loss = 39039305430.61918\n",
      "===Epoch 166===\n",
      "average loss = 39039304824.63562\n",
      "===Epoch 167===\n",
      "average loss = 39039305834.60822\n",
      "===Epoch 168===\n",
      "average loss = 39039304824.63562\n",
      "===Epoch 169===\n",
      "average loss = 39039304386.98082\n",
      "===Epoch 170===\n",
      "average loss = 39039304667.52877\n",
      "===Epoch 171===\n",
      "average loss = 39039304678.75069\n",
      "===Epoch 172===\n",
      "average loss = 39039304678.75069\n",
      "===Epoch 173===\n",
      "average loss = 39039305105.18356\n",
      "===Epoch 174===\n",
      "average loss = 39039303982.99178\n",
      "===Epoch 175===\n",
      "average loss = 39039304381.369865\n",
      "===Epoch 176===\n",
      "average loss = 39039305324.010956\n",
      "===Epoch 177===\n",
      "average loss = 39039305049.073975\n",
      "===Epoch 178===\n",
      "average loss = 39039304521.64384\n",
      "===Epoch 179===\n",
      "average loss = 39039304241.095894\n",
      "===Epoch 180===\n",
      "average loss = 39039304263.53973\n",
      "===Epoch 181===\n",
      "average loss = 39039304330.87123\n",
      "===Epoch 182===\n",
      "average loss = 39039305453.06301\n",
      "===Epoch 183===\n",
      "average loss = 39039304392.59178\n",
      "===Epoch 184===\n",
      "average loss = 39039304398.20274\n",
      "===Epoch 185===\n",
      "average loss = 39039305324.010956\n",
      "===Epoch 186===\n",
      "average loss = 39039305307.178085\n",
      "===Epoch 187===\n",
      "average loss = 39039303825.88493\n",
      "===Epoch 188===\n",
      "average loss = 39039305464.284935\n",
      "===Epoch 189===\n",
      "average loss = 39039305307.178085\n",
      "===Epoch 190===\n",
      "average loss = 39039304454.31233\n",
      "===Epoch 191===\n",
      "average loss = 39039305239.84657\n",
      "===Epoch 192===\n",
      "average loss = 39039304611.41918\n",
      "===Epoch 193===\n",
      "average loss = 39039305138.84931\n",
      "===Epoch 194===\n",
      "average loss = 39039304241.095894\n",
      "===Epoch 195===\n",
      "average loss = 39039304173.76438\n",
      "===Epoch 196===\n",
      "average loss = 39039304948.07671\n",
      "===Epoch 197===\n",
      "average loss = 39039304785.3589\n",
      "===Epoch 198===\n",
      "average loss = 39039304128.87671\n",
      "===Epoch 199===\n",
      "average loss = 39039304768.526024\n",
      "===Epoch 200===\n",
      "average loss = 39039305161.29315\n",
      "===Epoch 201===\n",
      "average loss = 39039304241.095894\n",
      "===Epoch 202===\n",
      "average loss = 39039305138.84931\n",
      "===Epoch 203===\n",
      "average loss = 39039304588.97534\n",
      "===Epoch 204===\n",
      "average loss = 39039305699.945206\n",
      "===Epoch 205===\n",
      "average loss = 39039304465.53425\n",
      "===Epoch 206===\n",
      "average loss = 39039305138.84931\n",
      "===Epoch 207===\n",
      "average loss = 39039304633.863014\n",
      "===Epoch 208===\n",
      "average loss = 39039304925.63287\n",
      "===Epoch 209===\n",
      "average loss = 39039305093.96165\n",
      "===Epoch 210===\n",
      "average loss = 39039304633.863014\n",
      "===Epoch 211===\n",
      "average loss = 39039304835.85754\n",
      "===Epoch 212===\n",
      "average loss = 39039304779.74795\n",
      "===Epoch 213===\n",
      "average loss = 39039305273.51233\n",
      "===Epoch 214===\n",
      "average loss = 39039305217.40274\n",
      "===Epoch 215===\n",
      "average loss = 39039303825.88493\n",
      "===Epoch 216===\n",
      "average loss = 39039305396.95342\n",
      "===Epoch 217===\n",
      "average loss = 39039304622.6411\n",
      "===Epoch 218===\n",
      "average loss = 39039303870.772606\n",
      "===Epoch 219===\n",
      "average loss = 39039305060.29589\n",
      "===Epoch 220===\n",
      "average loss = 39039304319.649315\n",
      "===Epoch 221===\n",
      "average loss = 39039305105.18356\n",
      "===Epoch 222===\n",
      "average loss = 39039305071.51781\n",
      "===Epoch 223===\n",
      "average loss = 39039304364.53699\n",
      "===Epoch 224===\n",
      "average loss = 39039304981.74246\n",
      "===Epoch 225===\n",
      "average loss = 39039304207.43014\n",
      "===Epoch 226===\n",
      "average loss = 39039304398.20274\n",
      "===Epoch 227===\n",
      "average loss = 39039305082.73972\n",
      "===Epoch 228===\n",
      "average loss = 39039304712.416435\n",
      "===Epoch 229===\n",
      "average loss = 39039304869.523285\n",
      "===Epoch 230===\n",
      "average loss = 39039303904.438354\n",
      "===Epoch 231===\n",
      "average loss = 39039304297.20548\n",
      "===Epoch 232===\n",
      "average loss = 39039304386.98082\n",
      "===Epoch 233===\n",
      "average loss = 39039303898.8274\n",
      "===Epoch 234===\n",
      "average loss = 39039304914.41096\n",
      "===Epoch 235===\n",
      "average loss = 39039304869.523285\n",
      "===Epoch 236===\n",
      "average loss = 39039305228.62466\n",
      "===Epoch 237===\n",
      "average loss = 39039304751.69315\n",
      "===Epoch 238===\n",
      "average loss = 39039305144.46027\n",
      "===Epoch 239===\n",
      "average loss = 39039305565.28219\n",
      "===Epoch 240===\n",
      "average loss = 39039304431.86849\n",
      "===Epoch 241===\n",
      "average loss = 39039304835.85754\n",
      "===Epoch 242===\n",
      "average loss = 39039305251.0685\n",
      "===Epoch 243===\n",
      "average loss = 39039304213.0411\n",
      "===Epoch 244===\n",
      "average loss = 39039304532.86575\n",
      "===Epoch 245===\n",
      "average loss = 39039305026.630135\n",
      "===Epoch 246===\n",
      "average loss = 39039305228.62466\n",
      "===Epoch 247===\n",
      "average loss = 39039305857.052055\n",
      "===Epoch 248===\n",
      "average loss = 39039304353.31507\n",
      "===Epoch 249===\n",
      "average loss = 39039304544.08767\n",
      "===Epoch 250===\n",
      "average loss = 39039305105.18356\n",
      "===Epoch 251===\n",
      "average loss = 39039304342.09315\n",
      "===Epoch 252===\n",
      "average loss = 39039305082.73972\n",
      "===Epoch 253===\n",
      "average loss = 39039304847.07945\n",
      "===Epoch 254===\n",
      "average loss = 39039304981.74246\n",
      "===Epoch 255===\n",
      "average loss = 39039304358.926025\n",
      "===Epoch 256===\n",
      "average loss = 39039304465.53425\n",
      "===Epoch 257===\n",
      "average loss = 39039304802.19178\n",
      "===Epoch 258===\n",
      "average loss = 39039305037.85206\n",
      "===Epoch 259===\n",
      "average loss = 39039304454.31233\n",
      "===Epoch 260===\n",
      "average loss = 39039305307.178085\n",
      "===Epoch 261===\n",
      "average loss = 39039304880.74521\n",
      "===Epoch 262===\n",
      "average loss = 39039304117.65479\n",
      "===Epoch 263===\n",
      "average loss = 39039305194.9589\n",
      "===Epoch 264===\n",
      "average loss = 39039305542.838356\n",
      "===Epoch 265===\n",
      "average loss = 39039303949.32603\n",
      "===Epoch 266===\n",
      "average loss = 39039304061.545204\n",
      "===Epoch 267===\n",
      "average loss = 39039305531.61644\n",
      "===Epoch 268===\n",
      "average loss = 39039305385.73151\n",
      "===Epoch 269===\n",
      "average loss = 39039305307.178085\n",
      "===Epoch 270===\n",
      "average loss = 39039304880.74521\n",
      "===Epoch 271===\n",
      "average loss = 39039304027.879456\n",
      "===Epoch 272===\n",
      "average loss = 39039304549.69863\n",
      "===Epoch 273===\n",
      "average loss = 39039304981.74246\n",
      "===Epoch 274===\n",
      "average loss = 39039305105.18356\n",
      "===Epoch 275===\n",
      "average loss = 39039304824.63562\n",
      "===Epoch 276===\n",
      "average loss = 39039304521.64384\n",
      "===Epoch 277===\n",
      "average loss = 39039304992.964386\n",
      "===Epoch 278===\n",
      "average loss = 39039304948.07671\n",
      "===Epoch 279===\n",
      "average loss = 39039304633.863014\n",
      "===Epoch 280===\n",
      "average loss = 39039305318.4\n",
      "===Epoch 281===\n",
      "average loss = 39039305273.51233\n",
      "===Epoch 282===\n",
      "average loss = 39039304241.095894\n",
      "===Epoch 283===\n",
      "average loss = 39039304577.753426\n",
      "===Epoch 284===\n",
      "average loss = 39039304734.860275\n",
      "===Epoch 285===\n",
      "average loss = 39039305475.50685\n",
      "===Epoch 286===\n",
      "average loss = 39039305318.4\n",
      "===Epoch 287===\n",
      "average loss = 39039305262.29041\n",
      "===Epoch 288===\n",
      "average loss = 39039305946.8274\n",
      "===Epoch 289===\n",
      "average loss = 39039304802.19178\n",
      "===Epoch 290===\n",
      "average loss = 39039304701.19452\n",
      "===Epoch 291===\n",
      "average loss = 39039305150.071236\n",
      "===Epoch 292===\n",
      "average loss = 39039304095.21096\n",
      "===Epoch 293===\n",
      "average loss = 39039306036.60274\n",
      "===Epoch 294===\n",
      "average loss = 39039304970.520546\n",
      "===Epoch 295===\n",
      "average loss = 39039304308.4274\n",
      "===Epoch 296===\n",
      "average loss = 39039303780.99726\n",
      "===Epoch 297===\n",
      "average loss = 39039305419.39726\n",
      "===Epoch 298===\n",
      "average loss = 39039305127.627396\n",
      "===Epoch 299===\n",
      "average loss = 39039305015.40822\n",
      "===Epoch 300===\n",
      "average loss = 39039305138.84931\n",
      "===Epoch 301===\n",
      "average loss = 39039305823.3863\n",
      "===Epoch 302===\n",
      "average loss = 39039304566.53151\n",
      "===Epoch 303===\n",
      "average loss = 39039304011.04658\n",
      "===Epoch 304===\n",
      "average loss = 39039303915.66027\n",
      "===Epoch 305===\n",
      "average loss = 39039303971.76986\n",
      "===Epoch 306===\n",
      "average loss = 39039304252.31781\n",
      "===Epoch 307===\n",
      "average loss = 39039304992.964386\n",
      "===Epoch 308===\n",
      "average loss = 39039303511.671234\n",
      "===Epoch 309===\n",
      "average loss = 39039304381.369865\n",
      "===Epoch 310===\n",
      "average loss = 39039304005.435616\n",
      "===Epoch 311===\n",
      "average loss = 39039305340.843834\n",
      "===Epoch 312===\n",
      "average loss = 39039305251.0685\n",
      "===Epoch 313===\n",
      "average loss = 39039304678.75069\n",
      "===Epoch 314===\n",
      "average loss = 39039304353.31507\n",
      "===Epoch 315===\n",
      "average loss = 39039306002.93699\n",
      "===Epoch 316===\n",
      "average loss = 39039305509.1726\n",
      "===Epoch 317===\n",
      "average loss = 39039304886.35616\n",
      "===Epoch 318===\n",
      "average loss = 39039304790.969864\n",
      "===Epoch 319===\n",
      "average loss = 39039304302.81644\n",
      "===Epoch 320===\n",
      "average loss = 39039305767.27671\n",
      "===Epoch 321===\n",
      "average loss = 39039306081.49041\n",
      "===Epoch 322===\n",
      "average loss = 39039305194.9589\n",
      "===Epoch 323===\n",
      "average loss = 39039305385.73151\n",
      "===Epoch 324===\n",
      "average loss = 39039304645.08493\n",
      "===Epoch 325===\n",
      "average loss = 39039304151.32055\n",
      "===Epoch 326===\n",
      "average loss = 39039304785.3589\n",
      "===Epoch 327===\n",
      "average loss = 39039304858.30137\n",
      "===Epoch 328===\n",
      "average loss = 39039304667.52877\n",
      "===Epoch 329===\n",
      "average loss = 39039304959.29863\n",
      "===Epoch 330===\n",
      "average loss = 39039304555.309586\n",
      "===Epoch 331===\n",
      "average loss = 39039304027.879456\n",
      "===Epoch 332===\n",
      "average loss = 39039304106.43288\n",
      "===Epoch 333===\n",
      "average loss = 39039304510.42192\n",
      "===Epoch 334===\n",
      "average loss = 39039304858.30137\n",
      "===Epoch 335===\n",
      "average loss = 39039303797.83014\n",
      "===Epoch 336===\n",
      "average loss = 39039305531.61644\n",
      "===Epoch 337===\n",
      "average loss = 39039304454.31233\n",
      "===Epoch 338===\n",
      "average loss = 39039305711.16712\n",
      "===Epoch 339===\n",
      "average loss = 39039304835.85754\n",
      "===Epoch 340===\n",
      "average loss = 39039304241.095894\n",
      "===Epoch 341===\n",
      "average loss = 39039305138.84931\n",
      "===Epoch 342===\n",
      "average loss = 39039304936.8548\n",
      "===Epoch 343===\n",
      "average loss = 39039304050.32329\n",
      "===Epoch 344===\n",
      "average loss = 39039304903.18904\n",
      "===Epoch 345===\n",
      "average loss = 39039304645.08493\n",
      "===Epoch 346===\n",
      "average loss = 39039305082.73972\n",
      "===Epoch 347===\n",
      "average loss = 39039306070.26849\n",
      "===Epoch 348===\n",
      "average loss = 39039304617.030136\n",
      "===Epoch 349===\n",
      "average loss = 39039304521.64384\n",
      "===Epoch 350===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     35\u001b[0m total_bsz \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tf \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m     37\u001b[0m     tf \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     38\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(tf)\n",
      "File \u001b[0;32m/usr1/rzhai/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr1/rzhai/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr1/rzhai/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate_fn(data)\n",
      "File \u001b[0;32m/usr1/rzhai/anaconda3/envs/py311/lib/python3.11/site-packages/torch_frame/data/loader.py:54\u001b[0m, in \u001b[0;36mDataLoader.collate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollate_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: IndexSelectType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorFrame:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_frame[index]\n",
      "File \u001b[0;32m/usr1/rzhai/anaconda3/envs/py311/lib/python3.11/site-packages/torch_frame/data/tensor_frame.py:297\u001b[0m, in \u001b[0;36mTensorFrame.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x[index]\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(fn)\n",
      "File \u001b[0;32m/usr1/rzhai/anaconda3/envs/py311/lib/python3.11/site-packages/torch_frame/data/tensor_frame.py:348\u001b[0m, in \u001b[0;36mTensorFrame._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn: Callable[[TensorData], TensorData]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorFrame:\n\u001b[1;32m    347\u001b[0m     out \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m     out\u001b[38;5;241m.\u001b[39mfeat_dict \u001b[38;5;241m=\u001b[39m {stype: fn(x) \u001b[38;5;28;01mfor\u001b[39;00m stype, x \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39mfeat_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39my \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m         y \u001b[38;5;241m=\u001b[39m fn(out\u001b[38;5;241m.\u001b[39my)\n",
      "File \u001b[0;32m/usr1/rzhai/anaconda3/envs/py311/lib/python3.11/site-packages/torch_frame/data/tensor_frame.py:348\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn: Callable[[TensorData], TensorData]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorFrame:\n\u001b[1;32m    347\u001b[0m     out \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m     out\u001b[38;5;241m.\u001b[39mfeat_dict \u001b[38;5;241m=\u001b[39m {stype: fn(x) \u001b[38;5;28;01mfor\u001b[39;00m stype, x \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39mfeat_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39my \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m         y \u001b[38;5;241m=\u001b[39m fn(out\u001b[38;5;241m.\u001b[39my)\n",
      "File \u001b[0;32m/usr1/rzhai/anaconda3/envs/py311/lib/python3.11/enum.py:1207\u001b[0m, in \u001b[0;36mEnum.__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec):\n\u001b[1;32m   1205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m), format_spec)\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name_)\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__reduce_ex__\u001b[39m(\u001b[38;5;28mself\u001b[39m, proto):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: LinearEncoder(),\n",
    "}\n",
    "\n",
    "device = 'cuda:5'\n",
    "\n",
    "from torch_frame.nn.models.ft_transformer import FTTransformer\n",
    "\n",
    "# model = FTTransformer(\n",
    "#     channels=16,\n",
    "#     out_channels=1,\n",
    "#     num_layers=2,\n",
    "#     col_stats=dataset.col_stats,\n",
    "#     col_names_dict=dataset.tensor_frame.col_names_dict,\n",
    "#     stype_encoder_dict=stype_encoder_dict,\n",
    "# ).to(device)\n",
    "\n",
    "model = ExampleTransformer(\n",
    "    channels=32,\n",
    "    out_channels=1,\n",
    "    num_layers=2,\n",
    "    num_heads=8,\n",
    "    col_stats=dataset.col_stats,\n",
    "    col_names_dict=dataset.tensor_frame.col_names_dict,\n",
    ").to(device)\n",
    "\n",
    "train_loader = DataLoader(dataset.tensor_frame, batch_size=128,\n",
    "                          shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "for epoch in range(500):\n",
    "    print('===Epoch {}==='.format(epoch))\n",
    "    total_loss = 0\n",
    "    total_bsz = 0\n",
    "    for tf in train_loader:\n",
    "        tf = tf.to(device)\n",
    "        pred = model.forward(tf)\n",
    "        loss = F.mse_loss(pred, tf.y)\n",
    "        bsz = len(tf.y)\n",
    "        total_loss += loss.item() * bsz\n",
    "        total_bsz += bsz\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "    print('average loss = {}'.format(total_loss / total_bsz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3355],\n",
       "        [ 0.2470],\n",
       "        [ 0.1111],\n",
       "        ...,\n",
       "        [-0.3686],\n",
       "        [ 0.2081],\n",
       "        [-0.1134]], device='cuda:5', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(dataset.tensor_frame.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0792],\n",
       "        [-0.2398],\n",
       "        [-0.0740],\n",
       "        ...,\n",
       "        [-0.6281],\n",
       "        [-0.3431],\n",
       "        [-0.5273]], device='cuda:5', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file_path = \"data/house-prices/test.csv\"\n",
    "test_data = pd.read_csv(test_file_path)\n",
    "ids = test_data.pop('Id')\n",
    "\n",
    "test_data = prepare_dataset(test_data)\n",
    "col_to_stype = {key: stype.categorical for key in test_data.select_dtypes(include=['category']).columns.to_list()}\n",
    "col_to_stype.update({key: stype.numerical for key in test_data.select_dtypes(exclude=['category']).columns.to_list()})\n",
    "test_dataset = Dataset(test_data, col_to_stype=col_to_stype)\n",
    "test_dataset.materialize()\n",
    "\n",
    "model(test_dataset.tensor_frame.to(device))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
